{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bit65be82c22d0e493f990b2b0ad6e528de",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(4781, 122)\n(122,)\ntraining started...\nEpoch is:1 and Cost is: 3868.665978843504\nEpoch is:2 and Cost is: 4233.732348928373\nEpoch is:4 and Cost is: 4137.622756072837\ntraining finished.\nweights are: [ 0.22707604  0.05170326 -0.0875858  -0.12828119  0.55849134 -0.16499086\n  0.24607134  0.05076526  0.12717538  0.16739454  0.50336078 -0.24394646\n -0.01024385  0.08705834  0.24736715  0.20861977 -0.28603767 -0.52040917\n  0.5988822  -0.0884655   0.206416   -0.5044248  -0.50336078  0.26626028\n  0.00983467 -0.69977257 -0.06826554 -0.09061789 -0.08820239 -0.08820239\n -0.40480666 -0.40412704  0.08903637 -0.00937488  0.20667537  0.14626487\n  0.52238717 -0.14767453  0.24841104  0.34331969 -0.05074492  0.24394646\n  0.34486941 -0.24713567  0.26703234 -0.20671096 -0.16739454  0.04957686\n -0.02985129 -0.02985129 -0.28570525 -0.46206966  0.22446152 -0.18624456\n  0.05105232 -0.02979032  0.52376289  0.10809537 -0.11211233  0.62032043\n  0.01118349  0.06910629 -0.10912481 -0.28659868 -0.16734932  0.36662529\n  0.01077856 -0.12877582 -0.16677387  0.10921953 -0.06929083  0.67925278\n  0.18673558  0.20747714  0.28574274 -0.0096811   0.16857303 -0.1091062\n  0.03002914 -0.04939074 -0.30655957  0.16819863 -0.04953464  0.10953684\n -0.08911995  0.18843657 -0.24804507  0.30436999  0.16810491 -0.10864997\n  0.10887396  0.12821138  0.16825547  0.04965101  0.24762368 -0.18877164\n -0.06964799  0.0693157  -0.12898311 -0.07002367  0.00974934  0.12865162\n  0.08897862 -0.10895489 -0.02983112  0.00969405  0.34600127  0.10880218\n -0.02976321 -0.02995924  0.08895471  0.00974934  0.00974934 -0.06950978\n -0.08923503  0.08902192  0.00974934 -0.06944311  0.04959234 -0.03007024\n  0.00974934 -0.00974934]\n(4781,)\n(4781,)\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class LinearSVM(object):\n",
    "    def __init__(self, epochs):\n",
    "        self.x = pd.DataFrame()\n",
    "        self.y = np.array([])\n",
    "        self.weights = np.array([])\n",
    "        self.epochs = epochs\n",
    "        self.reg_strength = 10000\n",
    "        self.learning_rate = 0.000001\n",
    "        self.lamda = 1\n",
    "\n",
    "    def hingeloss(self, d, n):\n",
    "        return self.reg_strength*(np.sum(d)/n)\n",
    "\n",
    "    def get_cost(self, w, x, y):\n",
    "        n = x.shape[0]\n",
    "        dist = 1 - y*(np.dot(x, w))\n",
    "        dist[dist < 0] = 0\n",
    "        loss = self.hingeloss(dist, n)\n",
    "        cost = (self.lamda/2)*(np.dot(w, w)) + loss\n",
    "        return cost\n",
    "\n",
    "    def get_cost_gradient(self, W, X_batch, Y_batch):\n",
    "        if type(Y_batch) == np.float64:\n",
    "            Y_batch = np.array([Y_batch])\n",
    "            X_batch = np.array([X_batch])\n",
    "        dist = 1 - (Y_batch * np.dot(X_batch, W))\n",
    "        dw = np.zeros(len(W))\n",
    "        for index, d in enumerate(dist):\n",
    "            if max(0, d) == 0:\n",
    "                di = W\n",
    "            else:\n",
    "                di = W - (self.reg_strength * Y_batch[index] * X_batch[index])\n",
    "            dw += di\n",
    "        dw = dw/len(Y_batch)\n",
    "        return dw\n",
    "\n",
    "    def initialize(self, filename):\n",
    "        x, y = self.readfile(filename)\n",
    "        y = np.array(y)\n",
    "        x = np.array(x)\n",
    "        t = np.ones((np.size(x, 0), 1))\n",
    "        x = np.append(x, t, axis=1)\n",
    "        print(x.shape)\n",
    "        self.weights = np.zeros(np.size(x, 1))\n",
    "        print(self.weights.shape)\n",
    "        return x, y\n",
    "\n",
    "    def sgd(self, features, outputs):\n",
    "        max_epochs = self.epochs\n",
    "        nth = 0\n",
    "        prev_cost = float(\"inf\")\n",
    "        cost_threshold = 0.01\n",
    "        # stochastic gradient descent\n",
    "        for epoch in range(1, max_epochs):\n",
    "            # shuffle to prevent repeating update cycles\n",
    "            X, Y = shuffle(features, outputs)\n",
    "            for index, x in enumerate(X):\n",
    "                ascent = self.get_cost_gradient(self.weights, x, Y[index])\n",
    "                self.weights = self.weights - (self.learning_rate * ascent)\n",
    "            # convergence check on 2^nth epoch\n",
    "            if epoch == 2 ** nth or epoch == max_epochs - 1:\n",
    "                cost = self.get_cost(self.weights, features, outputs)\n",
    "                print(\"Epoch is:{} and Cost is: {}\".format(epoch, cost))\n",
    "                # stoppage criterion\n",
    "                if abs(prev_cost - cost) < cost_threshold * prev_cost:\n",
    "                    return self.weights\n",
    "                prev_cost = cost\n",
    "                nth += 1\n",
    "        return self.weights\n",
    "\n",
    "    def train(self, filename):\n",
    "        x, y = self.initialize(filename)\n",
    "        print(\"training started...\")\n",
    "        W = self.sgd(x, y)\n",
    "        print(\"training finished.\")\n",
    "        print(\"weights are: {}\".format(W))\n",
    "        prediction = []\n",
    "        for i in range(len(y)):\n",
    "            y_pred = np.sign(np.dot(x, self.weights))\n",
    "            prediction.append(y_pred)\n",
    "        return y, y_pred\n",
    "        # print(\"Training accuracy: \" + str(accuracy_score(y, prediction)))\n",
    "        # self.PerformanceMatrix(x, y, prediction)\n",
    "\n",
    "    def readfile(self, filename):\n",
    "        x = []\n",
    "        y = []\n",
    "        data = open(filename)\n",
    "        for index, line in enumerate(data):\n",
    "            line = line.split(None, 1)\n",
    "            if len(line) == 1:\n",
    "                line += ['']\n",
    "            label, features = line\n",
    "            y.append(float(label))\n",
    "            temp_x = {}\n",
    "            for elem in features.split(None):\n",
    "                name, value = elem.split(':')\n",
    "                temp_x[int(name)] = (float(value))\n",
    "            x = x + [temp_x]\n",
    "        x = pd.DataFrame(x).fillna(-1)\n",
    "        return x, y\n",
    "\n",
    "    def PerformanceMatrix(self, X, y_actual, y_pred):\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        for test_instance_result, label in zip(y_pred, y_actual):\n",
    "            if ((test_instance_result > 0.0) and (label > 0.0)):\n",
    "                tp += 1\n",
    "            if ((test_instance_result <= 0.0) and (label <= 0.0)):\n",
    "                tn += 1\n",
    "            if ((test_instance_result > 0.0) and (label <= 0.0)):\n",
    "                fp += 1\n",
    "            if ((test_instance_result <= 0.0) and (label > 0.0)):\n",
    "                fn += 1\n",
    "\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        recall = tp / (tp + fn + 0.00001)\n",
    "        precision = tp / (tp + fp + 0.00001)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 0.00001)\n",
    "        print(\"Accuracy:     \", accuracy)\n",
    "        print(\"Recall:       \", recall)\n",
    "        print(\"Precision:    \", precision)\n",
    "        print(\"F1:           \", f1)\n",
    "\n",
    "\n",
    "inference = LinearSVM(5)\n",
    "y, predictions = inference.train('Dataset/a4a.txt')\n",
    "# acc = accuracy_score(y, predictions)\n",
    "print(y.shape)\n",
    "print(predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.8389458272327965"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}